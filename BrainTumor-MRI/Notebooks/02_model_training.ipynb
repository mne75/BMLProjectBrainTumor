{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767e5569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Warsan Musse\\.conda\\envs\\ml\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "============================================================\n",
      "SECTION 1: SUPERVISED CNN WITH TRANSFER LEARNING\n",
      "============================================================\n",
      "Found 2870 images belonging to 2 classes.\n",
      "Found 394 images belonging to 2 classes.\n",
      "\n",
      " Training samples: 2870\n",
      " Test samples: 394\n",
      " Classes: {'no_tumor': 0, 'tumor': 1}\n",
      "WARNING:tensorflow:From c:\\Users\\Warsan Musse\\.conda\\envs\\ml\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Warsan Musse\\.conda\\envs\\ml\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Warsan Musse\\.conda\\envs\\ml\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"Tumor_Classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               2097408   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16812353 (64.13 MB)\n",
      "Trainable params: 2097665 (8.00 MB)\n",
      "Non-trainable params: 14714688 (56.13 MB)\n",
      "_________________________________________________________________\n",
      "\n",
      " Training supervised classifier...\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\Warsan Musse\\.conda\\envs\\ml\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Warsan Musse\\.conda\\envs\\ml\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "90/90 [==============================] - 410s 5s/step - loss: 0.3561 - accuracy: 0.8972 - val_loss: 0.5669 - val_accuracy: 0.6954\n",
      "Epoch 2/10\n",
      "11/90 [==>...........................] - ETA: 5:47 - loss: 0.1218 - accuracy: 0.9460"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# BRAIN TUMOR CLASSIFICATION & ANOMALY DETECTION\n",
    "# 02_model_training.ipynb\n",
    "# ============================================\n",
    "\n",
    "# Part 1: SUPERVISED LEARNING (VGG16)\n",
    "# Binary Classification: Tumor vs No Tumor\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SECTION 1: SUPERVISED CNN WITH TRANSFER LEARNING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create models directory\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "# Load data\n",
    "train_dir = \"../data/Training\"\n",
    "test_dir = \"../data/Testing\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"\\n Training samples: {train_data.samples}\")\n",
    "print(f\" Test samples: {test_data.samples}\")\n",
    "print(f\" Classes: {train_data.class_indices}\")\n",
    "\n",
    "# Load pretrained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom layers\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "], name='Tumor_Classifier')\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Train model\n",
    "print(\"\\n Training supervised classifier...\")\n",
    "history = model.fit(\n",
    "    train_data, \n",
    "    validation_data=test_data, \n",
    "    epochs=10,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot loss over epochs\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.legend()\n",
    "plt.title('Supervised Model Loss', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot accuracy over epochs\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.legend()\n",
    "plt.title('Supervised Model Accuracy', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/supervised_training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "model.save(\"../models/tumor_classifier_vgg16.keras\")\n",
    "print(\"\\n Supervised model saved: tumor_classifier_vgg16.keras\")\n",
    "print(f\" Final validation accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "\n",
    "# ============================================\n",
    "# SECTION 2: UNSUPERVISED LEARNING (AUTOENCODER)\n",
    "# Anomaly Detection: Trained only on healthy images\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SECTION 2: UNSUPERVISED AUTOENCODER FOR ANOMALY DETECTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Data augmentation for autoencoder\n",
    "train_datagen_ae = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load ONLY healthy images (no_tumor) for unsupervised learning\n",
    "train_data_healthy = train_datagen_ae.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='input',  # Autoencoder: output = input\n",
    "    classes=['no_tumor'],  # ONLY healthy brains!\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"\\n Healthy training samples: {train_data_healthy.samples}\")\n",
    "\n",
    "# Build Convolutional Autoencoder\n",
    "def build_autoencoder(input_shape=(150, 150, 3)):\n",
    "    \"\"\"Convolutional Autoencoder for image reconstruction\"\"\"\n",
    "    \n",
    "    input_img = layers.Input(shape=input_shape, name='input')\n",
    "    \n",
    "    # ENCODER\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)  # 75x75\n",
    "    \n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)  # 37x37\n",
    "    \n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    encoded = layers.MaxPooling2D((2, 2), padding='same')(x)  # 19x19\n",
    "    \n",
    "    # DECODER\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 38x38\n",
    "    \n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 76x76\n",
    "    \n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 152x152\n",
    "    \n",
    "    # Crop to 150x150 and reconstruct RGB\n",
    "    x = layers.Cropping2D(cropping=((1, 1), (1, 1)))(x)\n",
    "    decoded = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same', name='output')(x)\n",
    "    \n",
    "    return models.Model(input_img, decoded, name='Autoencoder')\n",
    "\n",
    "# Build and compile\n",
    "autoencoder = build_autoencoder()\n",
    "autoencoder.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "autoencoder.summary()\n",
    "\n",
    "# Callbacks\n",
    "callbacks_ae = [\n",
    "    EarlyStopping(monitor='loss', patience=5, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='loss', factor=0.5, patience=3, min_lr=1e-7, verbose=1)\n",
    "]\n",
    "\n",
    "# Train autoencoder\n",
    "print(\"\\n Training autoencoder on healthy images only...\")\n",
    "history_ae = autoencoder.fit(\n",
    "    train_data_healthy,\n",
    "    epochs=50,\n",
    "    steps_per_epoch=len(train_data_healthy),\n",
    "    callbacks=callbacks_ae,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot training progress\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_ae.history['loss'], label='Training Loss (MSE)', linewidth=2)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss (MSE)', fontsize=12)\n",
    "plt.title('Autoencoder Training Loss', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_ae.history['mae'], label='Training MAE', linewidth=2, color='orange')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('MAE', fontsize=12)\n",
    "plt.title('Mean Absolute Error', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/autoencoder_training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ… Final training loss: {history_ae.history['loss'][-1]:.6f}\")\n",
    "\n",
    "# Test reconstruction quality\n",
    "train_data_healthy.reset()\n",
    "sample_images, _ = next(train_data_healthy)\n",
    "reconstructed = autoencoder.predict(sample_images[:5], verbose=0)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i in range(5):\n",
    "    # Original\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(sample_images[i])\n",
    "    plt.title('Original', fontsize=10)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Reconstructed\n",
    "    plt.subplot(2, 5, i + 6)\n",
    "    plt.imshow(reconstructed[i])\n",
    "    error = np.mean(np.square(sample_images[i] - reconstructed[i]))\n",
    "    plt.title(f'Reconstructed\\nMSE: {error:.4f}', fontsize=10)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.suptitle('Reconstruction Quality on Healthy Brains', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/reconstruction_samples.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Calculate threshold for anomaly detection\n",
    "print(\"\\n Calculating optimal threshold...\")\n",
    "\n",
    "train_data_healthy.reset()\n",
    "all_healthy = []\n",
    "for i in range(len(train_data_healthy)):\n",
    "    batch, _ = next(train_data_healthy)\n",
    "    all_healthy.append(batch)\n",
    "all_healthy = np.concatenate(all_healthy)\n",
    "\n",
    "reconstructed_healthy = autoencoder.predict(all_healthy, verbose=0)\n",
    "errors_healthy = np.mean(np.square(all_healthy - reconstructed_healthy), axis=(1, 2, 3))\n",
    "\n",
    "mean_error = np.mean(errors_healthy)\n",
    "std_error = np.std(errors_healthy)\n",
    "threshold_95 = np.percentile(errors_healthy, 95)\n",
    "threshold_99 = np.percentile(errors_healthy, 99)\n",
    "\n",
    "print(f\"\\n Reconstruction Error Statistics (healthy images):\")\n",
    "print(f\"   Mean: {mean_error:.6f}\")\n",
    "print(f\"   Std:  {std_error:.6f}\")\n",
    "print(f\"   95th percentile: {threshold_95:.6f}\")\n",
    "print(f\"   99th percentile: {threshold_99:.6f}\")\n",
    "\n",
    "# Save threshold\n",
    "np.save('../models/anomaly_threshold.npy', threshold_95)\n",
    "print(f\"\\n Threshold saved: {threshold_95:.6f}\")\n",
    "\n",
    "# Plot error distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(errors_healthy, bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.axvline(threshold_95, color='red', linestyle='--', linewidth=2, \n",
    "            label=f'95th percentile: {threshold_95:.4f}')\n",
    "plt.axvline(mean_error, color='green', linestyle='--', linewidth=2, \n",
    "            label=f'Mean: {mean_error:.4f}')\n",
    "plt.xlabel('Reconstruction Error (MSE)', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title('Error Distribution on Healthy Images', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/error_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save autoencoder\n",
    "autoencoder.save(\"../models/autoencoder_abnormality.keras\")\n",
    "print(\"\\n Autoencoder saved: autoencoder_abnormality.keras\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" TRAINING COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nModels created:\")\n",
    "print(\"  1. tumor_classifier_vgg16.keras (Supervised)\")\n",
    "print(\"  2. autoencoder_abnormality.keras (Unsupervised)\")\n",
    "print(\"  3. anomaly_threshold.npy (Threshold for detection)\")\n",
    "print(\"\\n Next step: Run 03_evaluation.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
